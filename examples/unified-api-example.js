#!/usr/bin/env node

/**
 * OpenAI ç»Ÿä¸€æŽ¥å£ä½¿ç”¨ç¤ºä¾‹
 * 
 * æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ API Proxy çš„ç»Ÿä¸€ OpenAI è§„èŒƒæŽ¥å£
 * 
 * ä½¿ç”¨æ–¹æ³•ï¼š
 * 1. å¯åŠ¨ API Proxy æœåŠ¡ï¼šnpm start
 * 2. è¿è¡Œç¤ºä¾‹ï¼šnode examples/unified-api-example.js
 */

const axios = require('axios');

const BASE_URL = 'http://localhost:3000';

async function demonstrateUnifiedAPI() {
    console.log('ðŸš€ OpenAI ç»Ÿä¸€æŽ¥å£æ¼”ç¤º');
    console.log('========================\n');

    try {
        // 1. æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
        console.log('1. æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€...');
        const healthResponse = await axios.get(`${BASE_URL}/api/health`);
        console.log('âœ… æœåŠ¡çŠ¶æ€æ­£å¸¸:', healthResponse.data.message);
        console.log();

        // 2. èŽ·å–å¯ç”¨æ¨¡åž‹åˆ—è¡¨
        console.log('2. èŽ·å– OpenAI å…¼å®¹æ¨¡åž‹åˆ—è¡¨...');
        const modelsResponse = await axios.get(`${BASE_URL}/api/v1/models`);
        console.log('âœ… å¯ç”¨æ¨¡åž‹:');
        modelsResponse.data.data.forEach(model => {
            console.log(`   - ${model.id} (${model.owned_by})`);
        });
        console.log();

        // 3. èŽ·å–ç‰¹å®šæ¨¡åž‹ä¿¡æ¯
        console.log('3. èŽ·å– GPT-3.5-turbo æ¨¡åž‹è¯¦ç»†ä¿¡æ¯...');
        const modelResponse = await axios.get(`${BASE_URL}/api/v1/models/gpt-3.5-turbo`);
        console.log('âœ… æ¨¡åž‹ä¿¡æ¯:', JSON.stringify(modelResponse.data, null, 2));
        console.log();

        // 4. èŽ·å–æä¾›å•†èƒ½åŠ›ä¿¡æ¯
        console.log('4. èŽ·å–æä¾›å•†èƒ½åŠ›ä¿¡æ¯...');
        const capabilitiesResponse = await axios.get(`${BASE_URL}/api/providers/capabilities`);
        console.log('âœ… æ”¯æŒçš„æä¾›å•†:');
        capabilitiesResponse.data.data.forEach(provider => {
            console.log(`   - ${provider.display_name} (${provider.provider})`);
            console.log(`     æ¨¡åž‹æ•°é‡: ${provider.models.length}`);
            console.log(`     æ”¯æŒåŠŸèƒ½: èŠå¤©=${provider.supported_features.chat_completions}, æµå¼=${provider.supported_features.streaming}`);
        });
        console.log();

        // 5. æµ‹è¯•èŠå¤©å®Œæˆè¯·æ±‚éªŒè¯ï¼ˆæ—  API å¯†é’¥ï¼Œé¢„æœŸå¤±è´¥ï¼‰
        console.log('5. æµ‹è¯•è¯·æ±‚éªŒè¯ï¼ˆæ— æ¨¡åž‹å‚æ•°ï¼‰...');
        try {
            await axios.post(`${BASE_URL}/api/v1/chat/completions`, {
                messages: [{ role: 'user', content: 'Hello' }]
            });
        } catch (error) {
            if (error.response?.status === 400) {
                console.log('âœ… è¯·æ±‚éªŒè¯æ­£å¸¸å·¥ä½œ:', error.response.data.error.message);
            } else {
                console.log('âŒ æ„å¤–é”™è¯¯:', error.message);
            }
        }
        console.log();

        // 6. æµ‹è¯•å®Œæ•´çš„èŠå¤©è¯·æ±‚ï¼ˆæ—  API å¯†é’¥ï¼Œé¢„æœŸå¤±è´¥ä½†æ ¼å¼æ­£ç¡®ï¼‰
        console.log('6. æµ‹è¯•å®Œæ•´èŠå¤©è¯·æ±‚æ ¼å¼...');
        try {
            await axios.post(`${BASE_URL}/api/v1/chat/completions`, {
                model: 'gpt-3.5-turbo',
                messages: [
                    { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹' },
                    { role: 'user', content: 'è¯·ç”¨ä¸­æ–‡å›žç­”ï¼šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ' }
                ],
                max_tokens: 150,
                temperature: 0.7
            });
        } catch (error) {
            if (error.response?.status >= 400) {
                console.log('âœ… è¯·æ±‚æ ¼å¼æ­£ç¡®ï¼Œç­‰å¾… API å¯†é’¥é…ç½®åŽå¯æ­£å¸¸ä½¿ç”¨');
                console.log('   é”™è¯¯ä¿¡æ¯:', error.response?.data?.error?.message || error.message);
            }
        }
        console.log();

        // 7. æµ‹è¯•æŒ‡å®šæä¾›å•†
        console.log('7. æµ‹è¯•æŒ‡å®š Anthropic æä¾›å•†...');
        try {
            await axios.post(`${BASE_URL}/api/v1/chat/completions?provider=anthropic`, {
                model: 'gpt-3.5-turbo', // å°†è‡ªåŠ¨æ˜ å°„åˆ° Claude æ¨¡åž‹
                messages: [{ role: 'user', content: 'Hello from Anthropic!' }]
            });
        } catch (error) {
            console.log('âœ… æä¾›å•†é€‰æ‹©åŠŸèƒ½æ­£å¸¸ï¼Œæ ¼å¼è½¬æ¢å·²å°±ç»ª');
            console.log('   (éœ€è¦é…ç½® Anthropic API å¯†é’¥åŽå¯æ­£å¸¸ä½¿ç”¨)');
        }
        console.log();

        console.log('ðŸŽ‰ æ¼”ç¤ºå®Œæˆï¼');
        console.log('=============');
        console.log('');
        console.log('ðŸ“š ä½¿ç”¨æŒ‡å—:');
        console.log('1. é…ç½® API å¯†é’¥åŽå³å¯æ­£å¸¸ä½¿ç”¨æ‰€æœ‰åŠŸèƒ½');
        console.log('2. æ”¯æŒä½¿ç”¨æ ‡å‡† OpenAI å®¢æˆ·ç«¯åº“');
        console.log('3. è‡ªåŠ¨è¿›è¡Œæ¨¡åž‹æ˜ å°„å’Œæ ¼å¼è½¬æ¢');
        console.log('4. è¯¦ç»†æ–‡æ¡£è¯·æŸ¥çœ‹ docs/UNIFIED_API.md');

    } catch (error) {
        console.error('âŒ æ¼”ç¤ºå¤±è´¥:', error.message);
        console.log('è¯·ç¡®ä¿ API Proxy æœåŠ¡æ­£åœ¨è¿è¡Œ (npm start)');
    }
}

// JavaScript ç¤ºä¾‹ï¼šä½¿ç”¨ fetch API
function showJavaScriptExample() {
    console.log('\nðŸ“ JavaScript è°ƒç”¨ç¤ºä¾‹:');
    console.log('====================');
    console.log(`
// ä½¿ç”¨æ ‡å‡† fetch API
const response = await fetch('${BASE_URL}/api/v1/chat/completions', {
    method: 'POST',
    headers: {
        'Content-Type': 'application/json'
    },
    body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages: [
            { role: 'user', content: 'Hello, world!' }
        ],
        max_tokens: 150
    })
});

const data = await response.json();
console.log(data.choices[0].message.content);
`);
}

// Python ç¤ºä¾‹
function showPythonExample() {
    console.log('\nðŸ Python è°ƒç”¨ç¤ºä¾‹:');
    console.log('==================');
    console.log(`
import requests

response = requests.post('${BASE_URL}/api/v1/chat/completions', 
    headers={'Content-Type': 'application/json'},
    json={
        'model': 'gpt-3.5-turbo',
        'messages': [
            {'role': 'user', 'content': 'Hello, world!'}
        ],
        'max_tokens': 150
    }
)

data = response.json()
print(data['choices'][0]['message']['content'])
`);
}

// cURL ç¤ºä¾‹
function showCurlExample() {
    console.log('\nðŸ’» cURL è°ƒç”¨ç¤ºä¾‹:');
    console.log('================');
    console.log(`
curl -X POST ${BASE_URL}/api/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {"role": "user", "content": "Hello, world!"}
    ],
    "max_tokens": 150
  }'
`);
}

// è¿è¡Œæ¼”ç¤º
if (require.main === module) {
    demonstrateUnifiedAPI().then(() => {
        showJavaScriptExample();
        showPythonExample();
        showCurlExample();
    });
}

module.exports = { demonstrateUnifiedAPI };